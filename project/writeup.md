# Auto-Vectorization for Bril

## Introduction

In this project, I sought to bring auto-vectorization to the Bril language. I added a basic vector instruction set to the Bril language and implemented it in the reference interpreter as `brili-vc`. I then implemented various approaches towards vectorization, beginning with a naive form of vectorization which creates vector instructions whevever possible. I also implemented a form of vectorization based on local value numbering (LVN), which attempts to reuse vectors as much as possible. As a goal for this project, I wanted to develop correct vectorization algorithms, and measure how many vector instructions were created, and the degree of reuse of vectors. To measure correctness, I created my own test cases, and to measure how many vector instructions were created, I used the CS 6120 Bril Benchmarks, as well as my own contrived tests, and calculated the number of vector instructions that were generated by instrumenting the `brili-vc` interpreter.

## Vector Language

The design of the vector language was based off resources from several students who had previously taken CS 6120, as well as the LLVM vector language. The students' languages are located at [vril](https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/vril-vector-bril/), and [vector-instruction-support](https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/interpreter-vector-support/). The LLVM vector language can be found be found at [llvm-vector](https://llvm.org/docs/LangRef.html#vector-operations).

Using these resources, I specified a minimal vector language. Each vector is comprised of exactly 4 ints. To create a fresh vector, one can use the `veczero` command, which creates a vector with all lanes starting with a value of 0. Operations on vectors include `vecadd`, `vecsub`, `vecmul`, and `vecdiv`, which are similar to their single integer Bril counterparts, except that the vector operations operate on 4 integers at a time. `vecmove` copies the value in one vector register to another vector register. `vecmac` represents an operation multiplying two vectors, and then adding a vector offset. `vecneg` negates all the elements of a vector. Due to project limitations, neither `vecmac` nor `vecneg` were handled; however, it is possible to extend the vectorization to handle these 2 instructions. 

To interact between vector registers and normal registers. one can load into and store from vectors. For instance, the `vecload` instruction places one integer of data into a vector, at the specified index in the vector. Likewise, `vecstore` extracts one integer of data from a vector into a Bril pseudo-register. 

The vector language is simulated in the Bril interpreter. I implemented the vector registers as variables storing array of width 4. Each vector operation manipulates the array appropriately; for instance, `veczero` instantiates all the cells of the array to have value 0, `vecload v i d` loads data `d` into the array representing vector `v` at index `i` in the array, and `vecadd v1 v2` does element-wise addition on the arrays representing vectors `v1` and `v2`. The implementation of this interpreter is located in the files `bril-vc` and `brili-vc`.

## Vectorization

Vectorization is broken into several stages. The first stage is to preprocess the code, which enables the vectorization algorithms to have greater opportunities to create vectors. The second stage is to run the vectorization algorithms on the preprocessed basic blocks in the code, and create vectors, which then replace code in the basic block. 

### Preprocessing

Preprocessing is applied to the Bril code to allow for further optimization potential. Assuming no memory operations are present, the first preprocessing optimizations applied are simple dead code elimination (DCE), LVN, loop invariant code motion (LICM). Removing obviously dead instructions will and applying local value numbering will simplify the code, propagate constants, and eliminate common subexpressions, simplifying some of the vectorization later on. As a side note, the condition for non-present memory conditions is because my implementations do not handle memory operations for DCE, LVN or LICM.

Next, loops in the code are fully unrolled, if possible. Unrolling only applies to loops that have one iteration variable that is increasing by 1 or decreasing by 1. Further, the loop header must have exactly one branch condition, dependign on the iteration variable. The loop also must have only one exit, from the branch condition in the header. By unrolling the code, loops get expanded into long sequences of straight-line code without branches or jumps. Having straight line code allows for long sequences of instructions that can be identified as vectorizable, and the possibility that a vector may be used several times.

After unrolling, stores are then moved as late in the basic block as possible. Store movement depends on alias analysis, because a store can only move past another store or another load, assuming no aliasing. Moving stores later in the basic block allows for a greater opportunity of finding vectors, because vectors have to end when a store is identified.

Following moving stores, each basic block is canonicalized so that sequences of adds, divides, multiplies, and subtractions occur together as much as possible. This pass is used to identify potential vectors in a simple manner.

Finally, block coalescing is done to the control flow graph. When loop unrolling is complete, there maybe extraneous jumps in the control flow graph. Basic blocks connected by a jump are stitched together into a single block, assuming that the original target label of the jump is unused after the jump is eliminated. By coalescing the control flow graph, the vectorization algorithms are able to search longer jump-free sequences of instructions and possibly find more vectors than had the coalescing not been applied.

### Naive Vectorization

## Evaluation

## Conclusion
